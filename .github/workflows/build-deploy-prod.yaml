name: Build and Deploy - Production

on:
  push:
    branches:
      - main
    paths:
      - 'frontend/**'
      - 'k8s/helm/**'
  workflow_dispatch:

permissions:
  contents: read
  security-events: write
  actions: read

env:
  AWS_REGION: ap-south-1
  DOCKER_REPOSITORY: zeusdev27/myhello
  EKS_CLUSTER_NAME: nasa-eks
  NAMESPACE: prod
  ENVIRONMENT: production

jobs:
  build-and-deploy:
    name: Build and Deploy to Production
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://prod.nainika.store
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: |
            ${{ env.DOCKER_REPOSITORY }}:latest
            ${{ env.DOCKER_REPOSITORY }}:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          scan-ref: '${{ env.DOCKER_REPOSITORY }}:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results.sarif'
          exit-code: 0
        continue-on-error: true
      
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
        continue-on-error: true
      
      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
          kubectl cluster-info
      
      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.12.0'
      
      - name: Fix NGINX Ingress webhook certificate
        run: |
          echo "ğŸ”§ Fixing NGINX Ingress webhook certificate..."
          
          # Check if webhook exists
          if kubectl get validatingwebhookconfigurations ingress-nginx-admission >/dev/null 2>&1; then
            echo "Webhook exists, deleting to regenerate..."
            kubectl delete validatingwebhookconfigurations ingress-nginx-admission || true
            
            # Wait for webhook to be recreated
            sleep 10
            
            # Patch webhook to use proper CA bundle
            kubectl get validatingwebhookconfigurations ingress-nginx-admission -o json | \
              jq '.webhooks[0].clientConfig.caBundle = ""' | \
              kubectl apply -f - || true
          fi
          
          # Alternative: Patch the webhook to ignore TLS verification (temporary fix)
          kubectl patch validatingwebhookconfigurations ingress-nginx-admission \
            --type='json' \
            -p='[{"op":"replace","path":"/webhooks/0/failurePolicy","value":"Ignore"}]' || true
      
      - name: Pre-deployment checks
        run: |
          echo "ğŸ” Pre-deployment checks..."
          
          # Check if namespace exists
          kubectl get namespace ${{ env.NAMESPACE }} || kubectl create namespace ${{ env.NAMESPACE }}
          
          # Create/update Docker registry secret for pulling images
          kubectl create secret docker-registry regcred \
            --docker-server=https://index.docker.io/v1/ \
            --docker-username=${{ secrets.DOCKER_HUB_USERNAME }} \
            --docker-password=${{ secrets.DOCKER_HUB_ACCESS_TOKEN }} \
            --docker-email=${{ secrets.DOCKER_HUB_EMAIL }} \
            -n ${{ env.NAMESPACE }} \
            --dry-run=client -o yaml | kubectl apply -f -
          
          # Check cluster resources
          echo ""
          echo "ğŸ“Š Cluster Resources:"
          kubectl top nodes || echo "Metrics not available"
          
          echo ""
          echo "ğŸƒ Current pods in namespace:"
          kubectl get pods -n ${{ env.NAMESPACE }} || echo "No pods yet"
      
      - name: Deploy application (without Ingress)
        run: |
          echo "ğŸ“¦ Deploying application without Ingress..."
          
          # Deploy without waiting first to see if it's a timeout or real failure
          helm upgrade --install frontend-app-prod ./k8s/helm/frontend-app \
            -f ./k8s/helm/frontend-app/value-prod.yaml \
            -n ${{ env.NAMESPACE }} \
            --set image.tag=${{ github.sha }} \
            --set ingress.enabled=false \
            --timeout=10m \
            --atomic=false \
            --debug
          
          echo ""
          echo "âœ… Helm release created/updated"
          
          # Now wait for deployment manually with better feedback
          echo ""
          echo "â³ Waiting for deployment to be ready..."
          
          for i in {1..60}; do
            READY=$(kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
            DESIRED=$(kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0")
            
            echo "Attempt $i/60: Ready: $READY/$DESIRED"
            
            if [ "$READY" = "$DESIRED" ] && [ "$READY" != "0" ]; then
              echo "âœ… Deployment is ready!"
              break
            fi
            
            if [ $i -eq 60 ]; then
              echo "âŒ Timeout waiting for deployment"
              kubectl get pods -n ${{ env.NAMESPACE }}
              exit 1
            fi
            
            sleep 5
          done
      
      - name: Debug deployment issues
        if: failure()
        run: |
          echo "âŒ Deployment failed, gathering debug info..."
          
          echo ""
          echo "ğŸ“¦ Helm Release Status:"
          helm status frontend-app-prod -n ${{ env.NAMESPACE }} || true
          
          echo ""
          echo "ğŸƒ Pod Status:"
          kubectl get pods -n ${{ env.NAMESPACE }} -o wide
          
          echo ""
          echo "ğŸ“‹ Pod Details:"
          kubectl describe pods -n ${{ env.NAMESPACE }} -l app.kubernetes.io/name=frontend-app
          
          echo ""
          echo "ğŸ“ Pod Logs:"
          for pod in $(kubectl get pods -n ${{ env.NAMESPACE }} -l app.kubernetes.io/name=frontend-app -o jsonpath='{.items[*].metadata.name}'); do
            echo "=== Logs for $pod ==="
            kubectl logs $pod -n ${{ env.NAMESPACE }} --tail=50 || true
            echo ""
          done
          
          echo ""
          echo "ğŸ” Events:"
          kubectl get events -n ${{ env.NAMESPACE }} --sort-by='.lastTimestamp' | tail -20
          
          echo ""
          echo "ğŸ“Š ReplicaSets:"
          kubectl get rs -n ${{ env.NAMESPACE }} -l app.kubernetes.io/name=frontend-app
          
          echo ""
          echo "ğŸ¯ Deployment Status:"
          kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} -o yaml || true
          
          exit 1
      
      - name: Create Ingress separately with validation disabled
        run: |
          echo "ğŸŒ Creating Ingress resource..."
          
          # Create Ingress with inline YAML
          cat <<EOF | kubectl apply -f -
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: frontend-app-prod
            namespace: ${{ env.NAMESPACE }}
            annotations:
              nginx.ingress.kubernetes.io/rewrite-target: /
              nginx.ingress.kubernetes.io/ssl-redirect: "true"
              cert-manager.io/cluster-issuer: "letsencrypt-prod"
          spec:
            ingressClassName: nginx
            tls:
            - hosts:
              - prod.nainika.store
              secretName: prod-nainika-store-tls
            rules:
            - host: prod.nainika.store
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: frontend-app-prod
                      port:
                        number: 80
          EOF
      
      - name: Wait for deployment to be ready
        run: |
          echo "â³ Waiting for deployment to be ready..."
          kubectl rollout status deployment/frontend-app-prod -n ${{ env.NAMESPACE }} --timeout=300s
          
          echo "âœ… Deployment successful!"
          kubectl get pods -n ${{ env.NAMESPACE }} -l app.kubernetes.io/name=frontend-app
      
      - name: Check Ingress and certificate status
        run: |
          echo "ğŸ” Ingress Status:"
          kubectl get ingress -n ${{ env.NAMESPACE }}
          
          echo ""
          echo "ğŸ” Certificate Status:"
          kubectl get certificate -n ${{ env.NAMESPACE }} || echo "No certificates found yet"
          
          echo ""
          echo "ğŸŒ Service Status:"
          kubectl get svc -n ${{ env.NAMESPACE }}
          
          # Get LoadBalancer endpoint
          LB_ENDPOINT=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Not ready")
          echo ""
          echo "ğŸ“ LoadBalancer Endpoint: $LB_ENDPOINT"
          
          if [ "$LB_ENDPOINT" != "Not ready" ]; then
            echo ""
            echo "âš ï¸  IMPORTANT: Ensure DNS is configured:"
            echo "   prod.nainika.store â†’ $LB_ENDPOINT"
          fi
      
      - name: Deployment summary
        if: always()
        run: |
          echo "## ğŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Image Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Tag**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Repository**: \`${{ env.DOCKER_REPOSITORY }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Deployment Status" >> $GITHUB_STEP_SUMMARY
          
          if kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} >/dev/null 2>&1; then
            READY=$(kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} -o jsonpath='{.status.readyReplicas}')
            DESIRED=$(kubectl get deployment frontend-app-prod -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.replicas}')
            echo "- **Pods**: $READY/$DESIRED ready" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Access URL" >> $GITHUB_STEP_SUMMARY
          echo "- **URL**: https://prod.nainika.store" >> $GITHUB_STEP_SUMMARY
