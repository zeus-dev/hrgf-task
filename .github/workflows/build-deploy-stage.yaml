name: Build and Deploy - Stage

on:
  push:
    branches:
      - stage
    paths:
      - 'frontend/**'
      - 'k8s/helm/**'
  workflow_dispatch:

permissions:
  contents: read
  security-events: write
  actions: read

env:
  AWS_REGION: ap-south-1
  DOCKER_REPOSITORY: zeusdev27/myhello
  EKS_CLUSTER_NAME: nasa-eks
  NAMESPACE: stage
  ENVIRONMENT: stage

jobs:
  build-and-deploy:
    name: Build and Deploy to Stage
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Debug - Show environment
        run: |
          echo "üîç Debug Information:"
          echo "Repository: ${{ github.repository }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          echo "AWS Region: ${{ env.AWS_REGION }}"
          echo "EKS Cluster: ${{ env.EKS_CLUSTER_NAME }}"
          echo "Namespace: ${{ env.NAMESPACE }}"
          echo "Docker Repo: ${{ env.DOCKER_REPOSITORY }}"
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Debug - Show Docker info
        run: |
          echo "üê≥ Docker Information:"
          docker --version
          docker buildx version
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: |
            ${{ env.DOCKER_REPOSITORY }}:staging
            ${{ env.DOCKER_REPOSITORY }}:staging-${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Debug - Show built image
        run: |
          echo "üì¶ Built Docker images:"
          docker images ${{ env.DOCKER_REPOSITORY }}
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'image'
          scan-ref: '${{ env.DOCKER_REPOSITORY }}:staging-${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results.sarif'
          exit-code: 0
      
      - name: Debug - Trivy scan results
        run: |
          echo "üîç Trivy scan completed"
          if [ -f trivy-results.sarif ]; then
            echo "SARIF file created successfully"
            ls -la trivy-results.sarif
            # Check if file has content
            if [ -s trivy-results.sarif ]; then
              echo "SARIF file has content"
              head -20 trivy-results.sarif
            else
              echo "SARIF file is empty - creating minimal valid SARIF"
              echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"Trivy","version":"0.0.0","informationUri":"https://github.com/aquasecurity/trivy"}},"results":[]}]}' > trivy-results.sarif
            fi
          else
            echo "SARIF file not found - creating minimal valid SARIF"
            echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"Trivy","version":"0.0.0","informationUri":"https://github.com/aquasecurity/trivy"}},"results":[]}]}' > trivy-results.sarif
          fi
      
      - name: Validate SARIF file
        run: |
          echo "üîç Validating SARIF file..."
          if [ -f trivy-results.sarif ]; then
            # Check if it's valid JSON
            if jq empty trivy-results.sarif 2>/dev/null; then
              echo "‚úÖ SARIF file is valid JSON"
              # Check if it has the required SARIF structure
              if jq -e '.version and .runs' trivy-results.sarif >/dev/null 2>&1; then
                echo "‚úÖ SARIF file has required structure"
              else
                echo "‚ùå SARIF file missing required fields, recreating..."
                echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"Trivy","version":"0.0.0","informationUri":"https://github.com/aquasecurity/trivy"}},"results":[]}]}' > trivy-results.sarif
              fi
            else
              echo "‚ùå SARIF file is not valid JSON, recreating..."
              echo '{"version":"2.1.0","$schema":"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json","runs":[{"tool":{"driver":{"name":"Trivy","version":"0.0.0","informationUri":"https://github.com/aquasecurity/trivy"}},"results":[]}]}' > trivy-results.sarif
            fi
          else
            echo "‚ùå SARIF file not found"
            exit 1
          fi
      
      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always() && github.repository == github.event.repository.full_name && github.event.repository.private == false
        with:
          sarif_file: 'trivy-results.sarif'
          token: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
      
      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
      
      - name: Debug - Show cluster info
        run: |
          echo "‚ò∏Ô∏è Kubernetes Cluster Information:"
          kubectl cluster-info
          kubectl get nodes
          kubectl get namespaces
      
      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.12.0'
      
      - name: Debug - Helm version
        run: |
          echo "‚öìÔ∏è Helm Information:"
          helm version
          helm repo list
      
      - name: Deploy to Stage with Helm
        run: |
          helm upgrade --install frontend-app-stage ./k8s/helm/frontend-app \
            --namespace ${{ env.NAMESPACE }} \
            --create-namespace \
            -f ./k8s/helm/frontend-app/value-stage.yaml \
            --set image.tag=staging-${{ github.sha }} \
            --wait \
            --timeout 10m
      
      - name: Debug - Deployment status
        run: |
          echo "üöÄ Deployment Status:"
          kubectl get pods -n ${{ env.NAMESPACE }}
          kubectl get svc -n ${{ env.NAMESPACE }}
          kubectl get ingress -n ${{ env.NAMESPACE }}
      
      - name: Verify Deployment
        run: |
          kubectl rollout status deployment/frontend-app-stage -n ${{ env.NAMESPACE }} --timeout=300s
          kubectl get pods -n ${{ env.NAMESPACE }} -l app.kubernetes.io/name=frontend-app
          kubectl get svc -n ${{ env.NAMESPACE }}
          kubectl get ingress -n ${{ env.NAMESPACE }}
      
      - name: Run Health Check
        run: |
          # Wait for deployment to be ready
          sleep 30
          # Check if the service is accessible (you may need to adjust this based on your setup)
          kubectl get endpoints -n ${{ env.NAMESPACE }}
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=frontend-app -n ${{ env.NAMESPACE }} --timeout=300s
          echo "Deployment successful!"
